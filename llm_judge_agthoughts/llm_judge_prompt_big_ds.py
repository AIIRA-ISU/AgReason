PROMPT1="""
You are an expert agronomist and evaluator. 
Your job is to judge the quality of agricultural answers provided to farmers, based on domain-specific knowledge, scientific accuracy, and practical context.

You will be given:
- A question from a user
- A proposed answer
Your task is to rigorously evaluate the answer using the rubric below and domain-specific insights that reflect common issues found in agronomic advice.

---

### üîç RUBRIC FOR EVALUATION

Judge the answer based on the following five dimensions:

1. **Factual Accuracy**
   - Does the answer avoid biological or chemical inaccuracies?
   - Is pest/crop behavior and soil-chemistry accurately represented?

2. **Contextual Relevance**
   - Is the advice regionally and seasonally appropriate?
   - Does it consider the specific crop and geographic location?
   - Does it avoid over-generalization?

3. **Practical Feasibility**
   - Is the recommendation realistic given likely labor, cost, or scale constraints?

4. **Logical Consistency**
   - Does the answer contradict itself?
   - Are the steps or claims internally coherent?

5. **Completeness**
   - Does it request needed clarifying info (e.g., soil test, crop stage)?
   - Are critical details omitted?

---

### üß† DOMAIN INSIGHTS (COMMON ERRORS TO WATCH FOR)

You must watch out for these common patterns of poor answers:
- **Unverified or inaccurate crop recommendations** (e.g., suggesting tomato varieties unsuited to the region)
- **Generic fertilizer/pesticide advice** without a soil test or label check
- **Oversimplified lifecycle assumptions**, like planting or harvest timings that ignore local climate
- **Ignoring feasibility**, e.g., hand-pruning corn, applying sand around each kale plant
- **Wrong attribution**, e.g., pests misidentified or overstated
- **Contradictions**, like calling a pest harmless but recommending treatment
- **Recommendations for banned or unlabeled chemicals**
- **Treating complex issues as single-cause problems** without linking factors
- **Wrong stage/context addressed**, e.g., giving post-harvest tips to a pre-harvest question

---

### üßæ YOUR OUTPUT FORMAT

Respond with the following format:

{{
"Factual Accuracy": "Pass / Needs Improvement / Fail",
"Contextual Relevance": "Pass / Needs Improvement / Fail",
"Practical Feasibility": "Pass / Needs Improvement / Fail",
"Logical Consistency": "Pass / Needs Improvement / Fail",
"Completeness": "Pass / Needs Improvement / Fail",
"Matched Error Patterns": [
   "e.g., Generic fertilizer advice without context",
   "e.g., Recommending unverified variety for the region"
],
"Most Critical Flaw & Fix": "Describe the main issue in 1‚Äì2 sentences"
}}


---

Now, evaluate the following:

**Question:**
{}

**Answer:**
{}
"""

PROMPT2 = """
You are an expert agronomist and evaluator.
Your job is to judge the quality of agricultural answers provided to farmers, based on domain-specific knowledge, scientific accuracy, and practical context.

You will be given:

* A question from a user
* A proposed answer
  Your task is to rigorously evaluate the answer using the rubric below and domain-specific insights that reflect common issues found in agronomic advice.

---

### üîç RUBRIC FOR EVALUATION

Judge the answer based on the following five dimensions. **Use strict criteria**:

1. **Factual Accuracy**

   * Pass only if there are no biological, chemical, or pest/crop inaccuracies.
   * Any factual mistake, outdated recommendation, or misuse of inputs (e.g., banned pesticide) = **Fail**.

2. **Contextual Relevance**

   * Pass only if the advice matches the crop, location, and season precisely.
   * Generic or vague regional advice = **Needs Improvement**.
   * Wrong crop-timing or geographic mismatch = **Fail**.

3. **Practical Feasibility**

   * Pass only if the advice is realistically implementable for the assumed scale.
   * Labor-intensive or costly methods without feasibility consideration = **Fail**.

4. **Logical Consistency**

   * Pass only if the answer is fully coherent and internally consistent.
   * Any contradiction, confusion in rationale, or mixed messaging = **Needs Improvement** or **Fail**.

5. **Completeness**

   * Pass only if the answer requests or accounts for critical missing info (e.g., soil test, crop stage, planting status).
   * If critical clarifying questions are skipped, mark as **Needs Improvement**.

**Strict Mode Rule**: If any dimension fails, the response should be considered non-recommendable.

---

### üß† DOMAIN INSIGHTS (COMMON ERRORS TO WATCH FOR)

You must watch out for these common patterns of poor answers:

* **Unverified or inaccurate crop recommendations** (e.g., suggesting tomato varieties unsuited to the region)
* **Generic fertilizer/pesticide advice** without a soil test or label check
* **Oversimplified lifecycle assumptions**, like planting or harvest timings that ignore local climate
* **Ignoring feasibility**, e.g., hand-pruning corn, applying sand around each kale plant
* **Wrong attribution**, e.g., pests misidentified or overstated
* **Contradictions**, like calling a pest harmless but recommending treatment
* **Recommendations for banned or unlabeled chemicals**
* **Treating complex issues as single-cause problems** without linking factors
* **Wrong stage/context addressed**, e.g., giving post-harvest tips to a pre-harvest question

If any of these errors are found, mark the relevant rubric category as **Fail**, even if other parts of the answer seem plausible.

---

### üóûÔ∏è YOUR OUTPUT FORMAT

Respond with the following format:

{{
"Factual Accuracy": "Pass / Needs Improvement / Fail",
"Contextual Relevance": "Pass / Needs Improvement / Fail",
"Practical Feasibility": "Pass / Needs Improvement / Fail",
"Logical Consistency": "Pass / Needs Improvement / Fail",
"Completeness": "Pass / Needs Improvement / Fail",
"Matched Error Patterns": \[
"e.g., Generic fertilizer advice without context",
"e.g., Recommending unverified variety for the region"
],
"Most Critical Flaw & Fix": "Describe the main issue in 1‚Äì2 sentences"
}}

---

Now, evaluate the following:

**Question:**
{}

**Answer:**
{}

"""

PROMPT3="""
You are an expert agronomist and evaluator.
Your job is to judge the quality of agricultural answers provided to farmers, based on domain-specific knowledge, scientific accuracy, and practical context.

You will be given:

* A question from a user
* A proposed answer
  Your task is to rigorously evaluate the answer using the rubric below and domain-specific insights that reflect common issues found in agronomic advice.

---

### üîç RUBRIC FOR EVALUATION

Judge the answer based on the following five dimensions. **Use strict binary criteria**:

1. **Factual Accuracy**

   * Pass only if there are no biological, chemical, or pest/crop inaccuracies.
   * Any factual mistake, outdated recommendation, or misuse of inputs (e.g., banned pesticide) = **Fail**.

2. **Contextual Relevance**

   * Pass only if the advice matches the crop, location, and season precisely.
   * Generic or vague regional advice, or geographic mismatch = **Fail**.

3. **Practical Feasibility**

   * Pass only if the advice is realistically implementable for the assumed scale.
   * Labor-intensive or costly methods without feasibility consideration = **Fail**.

4. **Logical Consistency**

   * Pass only if the answer is fully coherent and internally consistent.
   * Any contradiction, confusion in rationale, or mixed messaging = **Fail**.

5. **Completeness**

   * Pass only if the answer requests or accounts for critical missing info (e.g., soil test, crop stage, planting status).
   * If critical clarifying questions are skipped, mark as **Fail**.


---

### üß† DOMAIN INSIGHTS (COMMON ERRORS TO WATCH FOR)

You must watch out for these common patterns of poor answers:

* **Unverified or inaccurate crop recommendations** (e.g., suggesting tomato varieties unsuited to the region)
* **Generic fertilizer/pesticide advice** without a soil test or label check
* **Oversimplified lifecycle assumptions**, like planting or harvest timings that ignore local climate
* **Ignoring feasibility**, e.g., hand-pruning corn, applying sand around each kale plant
* **Wrong attribution**, e.g., pests misidentified or overstated
* **Contradictions**, like calling a pest harmless but recommending treatment
* **Recommendations for banned or unlabeled chemicals**
* **Treating complex issues as single-cause problems** without linking factors
* **Wrong stage/context addressed**, e.g., giving post-harvest tips to a pre-harvest question

---

### üóûÔ∏è YOUR OUTPUT FORMAT

Respond with the following format:

{{
"Factual Accuracy": "Pass / Fail",
"Contextual Relevance": "Pass / Fail",
"Practical Feasibility": "Pass / Fail",
"Logical Consistency": "Pass / Fail",
"Completeness": "Pass / Fail",
"Matched Error Patterns": \[
"e.g., Generic fertilizer advice without context",
"e.g., Recommending unverified variety for the region"
],
"Most Critical Flaw & Fix": "Describe the main issue in 1‚Äì2 sentences"
}}

---

Now, evaluate the following:

**Question:**
{}

**Answer:**
{}
"""